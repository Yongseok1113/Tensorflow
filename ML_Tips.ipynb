{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Learning rate :\n",
    "다음 데이터 실행할 때 이동하는 정도.\n",
    "보폭.\n",
    "\n",
    "    Large learning rate : overshooting\n",
    "        값이 너무 큰 경우 최적화 값에 도달하기 어려움.\n",
    "        cost값이 발산하게 됨.\n",
    "\n",
    "    Small learning rate : 최적 값을 찾는데 너무 많은 학습이 걸림.\n",
    "\n",
    "Data preprocessing for gradient descent\n",
    "    데이터들 간 값이 많이 차이날 경우 learning rate 가 적절해도 발산 할 수 있음.\n",
    "    등고선이 타원형인 경우..?\n",
    "    \n",
    "    Standardization\n",
    "    x_std[:,0] = (x[:,0] - x[:,0].mean()) / x[:,0].std()\n",
    "\n",
    "overfitting(과대적합)\n",
    "    너무 적합하도록 학습시키면 일반화가 낮아짐\n",
    "    해결방법 : 많은 트레이닝 데이터, 특징 갯수 줄임, regularization\n",
    "    \n",
    "    regularization : Let's  not have too big numbers in the weight\n",
    "    Loss + 람다 * (W제곱값들의 합(시그마))\n",
    "    람다값이 0이면 regularization을 사용하지 않겠다. 1이면 매우 중요하게 생각한다. \n",
    "    \n",
    "    l2reg = 0.001 * tf.reduce_sum(tf.square(W))\n",
    "    \n",
    "    \n",
    "performance evaluation 방법\n",
    "\n",
    "실제 데이터 셋에서 트레이닝 셋과 테스트 셋으로 나눈 후 트레이닝 셋만 학습시킨다. \n",
    "\n",
    "그 다음 테스트 셋으로 실행시켜 나온 예측값이 실제 데이터 셋의 결과와 일치하는 정도로 판단한다.\n",
    "\n",
    "\n",
    "online learning\n",
    "\n",
    "매우 큰 데이터 셋을 학습시킬 때 사용\n",
    "\n",
    "데이터셋을 일정 크기로 잘라 학습\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
