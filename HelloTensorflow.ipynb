{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#콘스탄트라는 노드 생성. 노드 이름은 hi, 노드 데이터는 헬로 텐서플로!\n",
    "hi = tf.constant(\"hello! tensorflow!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#세션 생성\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'hello! tensorflow!'\n"
     ]
    }
   ],
   "source": [
    "#세션을 통해 hi라는 노드 실행\n",
    "print(sess.run(hi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello! tensorflow!\n"
     ]
    }
   ],
   "source": [
    "print(str(sess.run(hi), encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#두 노드를 만들어 하나로 합하는 그래프 생성\n",
    "node1 = tf.constant(3.0, tf.float32)\n",
    "node2 = tf.constant(4.0) #also tf.float32 implicitly\n",
    "node3 = tf.add(node1, node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1 :  Tensor(\"Const_3:0\", shape=(), dtype=float32) node2 :  Tensor(\"Const_4:0\", shape=(), dtype=float32)\n",
      "node3 :  Tensor(\"Add_5:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#출력\n",
    "print(\"node1 : \", node1, \"node2 : \", node2)\n",
    "print(\"node3 : \", node3)\n",
    "#결과값이 나오지 않음. 단지 세 개의 텐서가 존재한다고 알려줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sess.run([node1, node2]) : [3.0, 4.0]\n",
      "sess.run(node3) :  7.0\n"
     ]
    }
   ],
   "source": [
    "#결과값을 확인하기 위해서는 세션을 통해 실행시켜야 한다.\n",
    "sess = tf.Session()\n",
    "print(\"sess.run([node1, node2]) : {0}\".format(sess.run([node1, node2])))\n",
    "print(\"sess.run(node3) : \", sess.run(node3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[3. 7.]\n"
     ]
    }
   ],
   "source": [
    "#실행시키는 과정에서 값을 넣을 때 \n",
    "\n",
    "node1 = tf.placeholder(tf.float32)\n",
    "node2 = tf.placeholder(tf.float32)\n",
    "adder_node = node1 + node2\n",
    "\n",
    "print(sess.run(adder_node, feed_dict={node1:3, node2:4.5}))\n",
    "print(sess.run(adder_node, feed_dict={node1:[1,3], node2:[2,4]}))\n",
    "#실행 도중에 값을 수정한다는게 중요한 것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n텐서플로우는 그래프를 정의하고,  정의한 그래프에 값을 주입해 , 실행한다.\\n텐스(Tense)는 기본적으로 Array를 말함. Ranks, Shapes, Types 가 있다.\\n\\n- Rank는 차원과 유사\\n랭크 0 : 스칼라    (magnitude only)           -> s = 483\\n랭크 1 : 벡터      (magnitude and direction)  -> v = [1.1, 2.2, 3.3]\\n랭크 2 : 매트릭스  (table of numbers)         -> m = [[1,2,3], [4,5,6], [7,8,9]]\\n\\n랭크 3 : 3-Tensor  (cube of numbers)          -> t = [ [ [2], [4], [6] ], [ [8], [10], [12] ] ]\\n...\\n랭크 n : n-Tensor  (your idea)\\n\\n- Shape는 각 엘리먼트에 몇개씩 들어있느냐?\\nRank 0 : []\\nRank 1 : [D0]\\nRank 2 : [D0, D1]\\nRank 3 : [D0, D1, D2]\\n\\nex) \\nt = [[1,2,3], [4,5,6], [7,8,9]] 요소 3개인 배열이 3개 있음\\nshape = [3, 3]\\n\\nt = [ [ [2], [4], [6] ], [ [8], [10], [12] ] ] 요소 1개인 배열이 3개 들어있는 배열이 2개 있음\\nshape = [1, 3, 2]\\n\\n- Type은 데이터 타입\\nDT_FLOAT => tf.float32\\nDT_DOUBLE => tf.float64\\nDT_INT8 => tf.int8\\nDT_INT16, 32, 64 => tf.int16, 32, 64\\n\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "텐서플로우는 그래프를 정의하고,  정의한 그래프에 값을 주입해 , 실행한다.\n",
    "텐스(Tense)는 기본적으로 Array를 말함. Ranks, Shapes, Types 가 있다.\n",
    "\n",
    "- Rank는 차원과 유사\n",
    "랭크 0 : 스칼라    (magnitude only)           -> s = 483\n",
    "랭크 1 : 벡터      (magnitude and direction)  -> v = [1.1, 2.2, 3.3]\n",
    "랭크 2 : 매트릭스  (table of numbers)         -> m = [[1,2,3], [4,5,6], [7,8,9]]\n",
    "\n",
    "랭크 3 : 3-Tensor  (cube of numbers)          -> t = [ [ [2], [4], [6] ], [ [8], [10], [12] ] ]\n",
    "...\n",
    "랭크 n : n-Tensor  (your idea)\n",
    "\n",
    "- Shape는 각 엘리먼트에 몇개씩 들어있느냐?\n",
    "Rank 0 : []\n",
    "Rank 1 : [D0]\n",
    "Rank 2 : [D0, D1]\n",
    "Rank 3 : [D0, D1, D2]\n",
    "\n",
    "ex) \n",
    "t = [[1,2,3], [4,5,6], [7,8,9]] 요소 3개인 배열이 3개 있음\n",
    "shape = [3, 3]\n",
    "\n",
    "t = [ [ [2], [4], [6] ], [ [8], [10], [12] ] ] 요소 1개인 배열이 3개 들어있는 배열이 2개 있음\n",
    "shape = [1, 3, 2]\n",
    "\n",
    "- Type은 데이터 타입\n",
    "DT_FLOAT => tf.float32\n",
    "DT_DOUBLE => tf.float64\n",
    "DT_INT8 => tf.int8\n",
    "DT_INT16, 32, 64 => tf.int16, 32, 64\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLinear Regression\\nSupervised Learning 을 통한 예측\\n1차원 그래프\\n\\n그래프상에서 실제 데이터들을 점들로 표현했을 때 \\n가설로 세운 1차 그래프에서 가까울 수록 가설이 좋음.\\n\\nCost(Loss) function\\n실제 데이터와 세운 가설이 얼마나 다른지 나타내는 그래프\\nH(x) - y -> 차이가 음수가 되거나 양수가 될 수 있기 때문에 좋지 않음\\n(H(x) -y)제곱이 좋음. 항상 양수로 표현되며, 값이 커질 수록(예측이 빗나간 정도가 클 수록) 더 강조 되기 때문\\n\\nH(x) = Wx + b일 때\\ncost(W,b) = 1/m * 시그마(i=1 ~ m까지) (H(x(i)) - y(i))제곱\\n\\ncost가 가장 작아지는 W,b값을 구하는 것이 Linear Regression의 목적\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.7480538 [-0.87709177] [2.5713599]\n",
      "20 1.0789725 [-0.25275996] [2.6863532]\n",
      "40 0.95885944 [-0.1428363] [2.5825613]\n",
      "60 0.8706601 [-0.08426639] [2.4633284]\n",
      "80 0.7907458 [-0.03284705] [2.3477647]\n",
      "100 0.7181682 [0.01573702] [2.237448]\n",
      "120 0.6522519 [0.0619979] [2.1322982]\n",
      "140 0.5923858 [0.10608076] [2.0320885]\n",
      "160 0.53801423 [0.14809175] [1.9365876]\n",
      "180 0.48863283 [0.18812843] [1.8455747]\n",
      "200 0.4437842 [0.22628346] [1.7588395]\n",
      "220 0.40305185 [0.26264533] [1.6761805]\n",
      "240 0.3660582 [0.29729828] [1.5974063]\n",
      "260 0.33246002 [0.33032262] [1.5223341]\n",
      "280 0.30194545 [0.36179498] [1.4507899]\n",
      "300 0.2742317 [0.39178833] [1.382608]\n",
      "320 0.24906166 [0.42037198] [1.3176308]\n",
      "340 0.22620173 [0.44761232] [1.255707]\n",
      "360 0.20544004 [0.47357255] [1.1966933]\n",
      "380 0.18658407 [0.49831268] [1.1404533]\n",
      "400 0.16945861 [0.52189004] [1.0868562]\n",
      "420 0.15390508 [0.54435945] [1.0357783]\n",
      "440 0.13977905 [0.5657728] [0.9871004]\n",
      "460 0.1269496 [0.5861799] [0.9407103]\n",
      "480 0.115297616 [0.605628] [0.89650035]\n",
      "500 0.10471512 [0.624162] [0.8543681]\n",
      "520 0.09510396 [0.64182496] [0.81421596]\n",
      "540 0.08637494 [0.6586579] [0.7759508]\n",
      "560 0.07844714 [0.6746997] [0.7394841]\n",
      "580 0.07124693 [0.68998766] [0.7047309]\n",
      "600 0.06470759 [0.70455706] [0.67161113]\n",
      "620 0.058768462 [0.7184418] [0.64004797]\n",
      "640 0.05337447 [0.731674] [0.609968]\n",
      "660 0.04847556 [0.74428433] [0.5813017]\n",
      "680 0.044026267 [0.7563021] [0.5539827]\n",
      "700 0.039985362 [0.767755] [0.5279474]\n",
      "720 0.03631532 [0.77866966] [0.5031359]\n",
      "740 0.032982185 [0.7890713] [0.47949046]\n",
      "760 0.029954934 [0.7989843] [0.45695615]\n",
      "780 0.027205558 [0.8084312] [0.43548086]\n",
      "800 0.024708524 [0.8174342] [0.4150149]\n",
      "820 0.022440681 [0.8260141] [0.39551076]\n",
      "840 0.02038099 [0.8341908] [0.37692323]\n",
      "860 0.01851034 [0.8419832] [0.3592092]\n",
      "880 0.016811399 [0.84940946] [0.34232768]\n",
      "900 0.015268358 [0.8564866] [0.32623956]\n",
      "920 0.013866987 [0.8632312] [0.31090754]\n",
      "940 0.012594216 [0.8696588] [0.29629606]\n",
      "960 0.011438258 [0.87578446] [0.28237116]\n",
      "980 0.0103884125 [0.88162214] [0.26910076]\n",
      "1000 0.00943494 [0.88718545] [0.25645405]\n",
      "1020 0.008568955 [0.8924873] [0.24440163]\n",
      "1040 0.007782463 [0.8975399] [0.23291568]\n",
      "1060 0.007068161 [0.90235525] [0.22196949]\n",
      "1080 0.0064194077 [0.90694416] [0.21153772]\n",
      "1100 0.0058302064 [0.91131747] [0.20159625]\n",
      "1120 0.0052950843 [0.9154852] [0.19212195]\n",
      "1140 0.0048090885 [0.9194572] [0.18309294]\n",
      "1160 0.0043676845 [0.92324233] [0.1744882]\n",
      "1180 0.003966796 [0.92684966] [0.1662879]\n",
      "1200 0.0036027096 [0.9302874] [0.15847301]\n",
      "1220 0.0032720491 [0.93356365] [0.15102533]\n",
      "1240 0.0029717237 [0.9366859] [0.14392771]\n",
      "1260 0.0026989726 [0.93966144] [0.13716365]\n",
      "1280 0.002451244 [0.94249713] [0.13071744]\n",
      "1300 0.002226255 [0.9451996] [0.12457419]\n",
      "1320 0.0020219234 [0.947775] [0.11871964]\n",
      "1340 0.001836345 [0.9502294] [0.11314031]\n",
      "1360 0.0016678004 [0.9525684] [0.10782313]\n",
      "1380 0.0015147192 [0.9547975] [0.10275584]\n",
      "1400 0.0013756932 [0.9569219] [0.0979267]\n",
      "1420 0.0012494283 [0.9589464] [0.09332455]\n",
      "1440 0.001134748 [0.96087575] [0.08893861]\n",
      "1460 0.0010306005 [0.96271443] [0.08475883]\n",
      "1480 0.0009360044 [0.96446675] [0.08077548]\n",
      "1500 0.0008500929 [0.9661367] [0.07697932]\n",
      "1520 0.00077206997 [0.9677281] [0.0733616]\n",
      "1540 0.0007012105 [0.96924466] [0.0699139]\n",
      "1560 0.00063684635 [0.9706902] [0.06662821]\n",
      "1580 0.0005783967 [0.9720676] [0.06349692]\n",
      "1600 0.0005253075 [0.9733803] [0.06051279]\n",
      "1620 0.00047709036 [0.97463137] [0.05766891]\n",
      "1640 0.00043330443 [0.9758236] [0.05495868]\n",
      "1660 0.00039353105 [0.9769598] [0.05237582]\n",
      "1680 0.00035741553 [0.97804254] [0.04991437]\n",
      "1700 0.0003246107 [0.9790744] [0.04756862]\n",
      "1720 0.00029481508 [0.9800579] [0.04533307]\n",
      "1740 0.00026775766 [0.98099506] [0.04320259]\n",
      "1760 0.00024318043 [0.9818883] [0.04117222]\n",
      "1780 0.0002208599 [0.98273945] [0.03923729]\n",
      "1800 0.00020058644 [0.98355067] [0.03739327]\n",
      "1820 0.00018217739 [0.9843236] [0.03563594]\n",
      "1840 0.00016545731 [0.9850604] [0.03396121]\n",
      "1860 0.00015027168 [0.98576254] [0.03236516]\n",
      "1880 0.00013647765 [0.98643166] [0.03084411]\n",
      "1900 0.00012395177 [0.9870693] [0.02939454]\n",
      "1920 0.00011257621 [0.987677] [0.0280131]\n",
      "1940 0.000102241196 [0.9882561] [0.02669661]\n",
      "1960 9.2859584e-05 [0.98880804] [0.02544199]\n",
      "1980 8.4335676e-05 [0.9893339] [0.02424633]\n",
      "2000 7.659604e-05 [0.9898352] [0.02310689]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.4295529e-12 [0.9999977] [4.721465e-06]\n",
      "20 3.4295529e-12 [0.9999977] [4.689678e-06]\n",
      "40 3.4295529e-12 [0.9999977] [4.657891e-06]\n",
      "60 3.4295529e-12 [0.99999774] [4.6284886e-06]\n",
      "80 3.4295529e-12 [0.99999774] [4.5967017e-06]\n",
      "100 3.2448118e-12 [0.99999774] [4.5768315e-06]\n",
      "120 3.2448118e-12 [0.99999774] [4.5609336e-06]\n",
      "140 3.2448118e-12 [0.99999774] [4.5450356e-06]\n",
      "160 3.2448118e-12 [0.99999774] [4.5291376e-06]\n",
      "180 3.2448118e-12 [0.99999774] [4.5132397e-06]\n",
      "200 3.2448118e-12 [0.99999774] [4.4973417e-06]\n",
      "220 3.2448118e-12 [0.99999774] [4.4814437e-06]\n",
      "240 3.2448118e-12 [0.9999978] [4.4671356e-06]\n",
      "260 3.2448118e-12 [0.9999978] [4.4512376e-06]\n",
      "280 3.2448118e-12 [0.9999978] [4.4353396e-06]\n",
      "300 3.2448118e-12 [0.9999978] [4.4194417e-06]\n",
      "320 3.2448118e-12 [0.99999785] [4.4027493e-06]\n",
      "340 3.2448118e-12 [0.99999785] [4.3868513e-06]\n",
      "360 3.2448118e-12 [0.99999785] [4.3709533e-06]\n",
      "380 3.2448118e-12 [0.99999785] [4.3550554e-06]\n",
      "400 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "420 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "440 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "460 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "480 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "500 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "520 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "540 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "560 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "580 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "600 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "620 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "640 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "660 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "680 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "700 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "720 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "740 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "760 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "780 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "800 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "820 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "840 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "860 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "880 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "900 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "920 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "940 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "960 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "980 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1000 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1020 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1040 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1060 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1080 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1100 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1120 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1140 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1160 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1180 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1200 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1220 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1240 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1260 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1280 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1300 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1320 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1340 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1360 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1380 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1400 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1420 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1440 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1460 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1480 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1500 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1520 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1540 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1560 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1580 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1600 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1620 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1640 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1660 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1680 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1700 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1720 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1740 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1760 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1780 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1800 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1820 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1840 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1860 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1880 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1900 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1920 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1940 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1960 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "1980 3.0695446e-12 [0.99999785] [4.351081e-06]\n",
      "2000 3.0695446e-12 [0.99999785] [4.351081e-06]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
