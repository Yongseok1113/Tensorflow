{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.71131563 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "100 0.69846034 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "200 0.69695175 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "300 0.69582367 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "400 0.6949391 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "500 0.6942109 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "600 0.6935792 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "700 0.69299984 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "800 0.69243777 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "900 0.6918617 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "1000 0.69124115 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "1100 0.69054335 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "1200 0.6897305 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "1300 0.6887567 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "1400 0.68756425 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "1500 0.68608 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "1600 0.68421084 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "1700 0.6818402 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "1800 0.6788261 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "1900 0.6750034 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "2000 0.67019534 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "2100 0.66423523 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "2200 0.65700233 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "2300 0.6484638 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "2400 0.6387081 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "2500 0.62795115 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "2600 0.61650103 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "2700 0.6046908 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "2800 0.59280044 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "2900 0.5809932 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "3000 0.56927663 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "3100 0.55748236 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "3200 0.545252 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "3300 0.5320195 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "3400 0.5169858 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "3500 0.49909842 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "3600 0.477079 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "3700 0.44962996 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "3800 0.4160158 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "3900 0.37693357 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "4000 0.3349012 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "4100 0.29339653 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "4200 0.25533873 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "4300 0.22223823 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "4400 0.19433755 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "4500 0.17116179 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "4600 0.15197925 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "4700 0.13605395 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "4800 0.12274644 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "4900 0.111535646 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "5000 0.10200873 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "5100 0.09384242 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "5200 0.08678435 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "5300 0.08063651 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "5400 0.07524276 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "5500 0.070479065 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "5600 0.06624583 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "5700 0.062462702 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "5800 0.0590643 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "5900 0.055996723 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "6000 0.05321572 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "6100 0.05068412 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "6200 0.04837081 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "6300 0.04624959 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "6400 0.044298124 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "6500 0.042497467 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "6600 0.0408312 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "6700 0.039285127 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "6800 0.03784713 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "6900 0.036506496 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "7000 0.035253882 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "7100 0.034081116 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "7200 0.03298092 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "7300 0.031947 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "7400 0.030973548 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "7500 0.030055651 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "7600 0.029188646 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "7700 0.028368635 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "7800 0.02759192 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "7900 0.026855174 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "8000 0.02615548 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "8100 0.02549022 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "8200 0.024856832 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "8300 0.02425327 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "8400 0.023677416 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "8500 0.023127481 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "8600 0.022601735 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "8700 0.022098655 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "8800 0.021616913 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "8900 0.021155123 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "9000 0.020712132 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "9100 0.020286802 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "9200 0.019878093 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "9300 0.01948513 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "9400 0.019106941 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "9500 0.01874284 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "9600 0.01839196 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "9700 0.01805368 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "9800 0.017727274 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "9900 0.017412215 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "10000 0.017107856 [[ 1.6148458 ]\n",
      " [-0.29242718]]\n",
      "\n",
      "Hypothesis: [[0.01992327]\n",
      " [0.98526335]\n",
      " [0.984063  ]\n",
      " [0.01724494]], \n",
      "Predicted: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]], \n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "y_data = [[0], [1], [1], [0]]\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2,2]), name='weight')\n",
    "b1 = tf.Variable(tf.random_normal([2]), name='bias')\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([2,1]), name='weight')\n",
    "b2 = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1-hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "for step in range(10001):\n",
    "    sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "    if step % 100 == 0:\n",
    "        print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run(W))\n",
    "\n",
    "h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X:x_data, Y:y_data})\n",
    "print(\"\\nHypothesis: {}, \\nPredicted: {}, \\nAccuracy: {}\".format(h, c, a))\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.98887026 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "100 0.70771545 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "200 0.7026194 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "300 0.69923675 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "400 0.6966244 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "500 0.6942328 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "600 0.6916671 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "700 0.6885972 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "800 0.6847229 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "900 0.6797303 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "1000 0.6732396 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "1100 0.6648126 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "1200 0.65407264 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "1300 0.6409017 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "1400 0.62561846 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "1500 0.6090278 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "1600 0.5922512 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "1700 0.5763817 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "1800 0.56217605 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "1900 0.54995745 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "2000 0.5397063 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "2100 0.5312119 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "2200 0.52419513 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "2300 0.5183784 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "2400 0.5135158 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "2500 0.5093994 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "2600 0.50585395 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "2700 0.50272584 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "2800 0.49986756 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "2900 0.49711427 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "3000 0.49424025 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "3100 0.4908788 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "3200 0.48637977 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "3300 0.47967535 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "3400 0.46945179 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "3500 0.45443082 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "3600 0.43280488 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "3700 0.4024119 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "3800 0.36261478 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "3900 0.3159628 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "4000 0.26790464 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "4100 0.22408725 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "4200 0.1876336 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "4300 0.15884434 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "4400 0.13652492 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "4500 0.119168654 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "4600 0.10548259 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "4700 0.09449591 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "4800 0.08551508 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "4900 0.07805012 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "5000 0.07175273 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "5100 0.066371545 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "5200 0.061721463 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "5300 0.057664026 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "5400 0.054093517 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "5500 0.050927907 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "5600 0.048102643 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "5700 0.045566127 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "5800 0.043276697 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "5900 0.04120034 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "6000 0.039308906 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "6100 0.037579097 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "6200 0.035991192 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "6300 0.034528743 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "6400 0.0331774 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "6500 0.031925313 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "6600 0.030761937 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "6700 0.029678315 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "6800 0.028666642 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "6900 0.027719958 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "7000 0.026832301 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "7100 0.025998443 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "7200 0.025213547 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "7300 0.02447356 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "7400 0.023774717 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "7500 0.023113739 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "7600 0.022487618 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "7700 0.02189375 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "7800 0.021329667 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "7900 0.020793214 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "8000 0.020282455 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "8100 0.019795494 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "8200 0.019330818 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "8300 0.018886935 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "8400 0.01846242 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "8500 0.018056132 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "8600 0.017666824 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "8700 0.017293535 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "8800 0.016935304 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "8900 0.016591154 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "9000 0.016260348 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "9100 0.015942112 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "9200 0.015635723 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "9300 0.015340578 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "9400 0.015056046 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "9500 0.014781525 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "9600 0.014516572 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "9700 0.014260662 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "9800 0.014013318 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "9900 0.013774142 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "10000 0.013542735 [[-0.62371427]\n",
      " [-0.6462628 ]]\n",
      "\n",
      "Hypothesis: [[0.01158929]\n",
      " [0.9837191 ]\n",
      " [0.99104726]\n",
      " [0.01696056]], \n",
      "Predicted: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]], \n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "y_data = [[0], [1], [1], [0]]\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2,10]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([10]), name='bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([10,5]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([5]), name='bias2')\n",
    "layer2 = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([5, 1]), name='weight3')\n",
    "b3 = tf.Variable(tf.random_normal([1]), name='bias3')\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer2, W3) + b3)\n",
    "\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1-hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "for step in range(10001):\n",
    "    sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "    if step % 100 == 0:\n",
    "        print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run(W))\n",
    "\n",
    "h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X:x_data, Y:y_data})\n",
    "print(\"\\nHypothesis: {}, \\nPredicted: {}, \\nAccuracy: {}\".format(h, c, a))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
